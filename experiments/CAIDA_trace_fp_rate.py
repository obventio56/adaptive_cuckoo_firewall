"""
Run ACF data structure on CAIDA traces

Example 1 (without sampling): 
    python CAIDA_run.py -input_trace trace.dat --no-sample
Example 2 (with sampling): 
    python CAIDA_run.py -input_trace trace.dat --sample -sample_rate 0.1

The preprocessed trace can be found  in this folder '/data/ACF' on TIMI server
- /data/ACF/equinix-chicago.dirA.20140619-130900.dat

"""

import math
import argparse
import threading
import matplotlib.pyplot as plt
from tqdm import tqdm
import pathlib
import json

from util import *
from supported_adaptations import ACF


# A/S ratio (Michael's sec4.2 experiment)
ratio_list = [i for i in range(1, 6)] + [i * 10 for i in range(1, 11)]
#ratio_list = [1]


def run_thread(tid, fiveTuple_list, ratio, n_flows, adapt, fingerprintLength, ratio2FP, ratio2FP_lock):
    """
    Calculate false positive rate of ACF
    parameters:
        tid: thread id
        fiveTuple_list: packet trace
        ratio: A/S ratio
        n_flows: #number of flows in packet trace
        ACF_c: number of cells per bucket in ACF
        ratio2FP: mapping between A/S ratio and FP rate
        ratio2FP_lock: lock associated with mapping
    """
    print("[Thread {}] ratio={} started".format(tid, ratio))
    fp_rate = 0.0
    FP = 0
    TN = 0

    # First, let's calculate the number of flows
    # for set A and set S
    S_flows = int(n_flows / (1 + max(ratio_list)))
    A_flows = S_flows*ratio

    print(S_flows, A_flows)

    b_val = math.ceil((S_flows / 0.8)/11)

    print(b_val)

    # Based on ACF paper, ACF reaches the
    # 95% load when it is filled with all S_flows
    acf = ACF(d=13, b=b_val,
              c=1, fingerprintLength=fingerprintLength)
    st = set()
    at = set()
    fp_set = set()

    insertionFailures = 0

    for fiveTuple in tqdm(fiveTuple_list, desc="[Thread {}]".format(tid)):
        fiveTuple = int.from_bytes(fiveTuple, byteorder="little")
        if len(st) <= S_flows:
            if fiveTuple not in st:
                if not acf.insert(fiveTuple):
                    insertionFailures += 1
                st.add(fiveTuple)
            # else:
                # Sanity check, flow should already be in filter
                # assert acf.check_membership(fiveTuple)

        if len(at) <= A_flows:
            if fiveTuple not in st:
                at.add(fiveTuple)

        if fiveTuple in st or fiveTuple in at:
            if acf.check_membership(fiveTuple):
                if fiveTuple not in st:
                    if fiveTuple not in fp_set:
                        fp_set.add(fiveTuple)

                    FP += 1
                    # Adapt to FP
                    if adapt == True:
                        acf.adapt_false_positive(fiveTuple)
                    #assert acf.check_membership(fiveTuple) == False
            else:
                if fiveTuple not in st:
                    TN += 1
    # Calculate FP
    fp_rate = FP / (FP + TN)
    # print(len(fp_set))
    #print(FP, TN)

    # Add this thread result to the shared mapping across threads
    with ratio2FP_lock:
        ratio2FP[ratio] = FP
    print("[Thread {}] ratio={} finished {} {} {} {}".format(
        tid, ratio, adapt, FP, TN, len(fp_set)))
    print(insertionFailures)


trace_paths = [
    ("1", "/data/ACF/equinix-chicago.dirA.20140619-130900.dat"),
    ("2", "/data/ACF/equinix-chicago.dirA.20140619-132600.dat"),
    ("3", "/data/ACF/equinix-sanjose.dirA.20140320-130400.dat"),
]

fingerprint_lengths = [
    0xff,
    # 0xfff,
    # 0xffff
]

if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="Run ACF data structure on CAIDA traces")
    parser.add_argument('-input_trace', type=str,
                        help="input CAIDA trace file")
    add_bool_arg(parser, "sample")
    parser.add_argument('-sample_rate', type=float,
                        default=0.1, help="the sample rate")
    args = parser.parse_args()

    for (traceLabel, tracePath) in trace_paths:

        # Load trace (generated by CAIDA/preprocess.py)
        fiveTuple_list = load_trace(
            tracePath, args.sample, args.sample_rate)

        # Get stats of this trace
        n_flows, n_pkts = get_trace_stats(fiveTuple_list)

        print(n_flows, n_pkts)

        """
        ratio2FP_lock = threading.Lock()
        ratio2FP = dict()
        run_thread(1, fiveTuple_list, 30, n_flows, True, 0xff, ratio2FP, ratio2FP_lock)

        print(ratio2FP)

        """

        for fingerprintLength in fingerprint_lengths:

            fig, ax = plt.subplots()
            C_list = [True, False]
            label_list = ["ACF", "CF"]
            marker_style_list = ["o", "v"]
            for marker_style, adapt_b, label_style in zip(marker_style_list, C_list, label_list):
                ratio2FP_lock = threading.Lock()
                ratio2FP = dict()
                # Parallel between different ratio
                thread_list = [threading.Thread(target=run_thread,
                                                args=(tid, fiveTuple_list, ratio, n_flows, adapt_b, fingerprintLength, ratio2FP, ratio2FP_lock))
                               for tid, ratio in enumerate(ratio_list)]
                for thread in thread_list:
                    thread.start()
                for thread in thread_list:
                    thread.join()

                fp_list = []
                for ratio in ratio_list:
                    fp_list.append(ratio2FP[ratio])
                ax.plot(ratio_list, fp_list, "-{}".format(marker_style),
                        fillstyle="none", label=label_style)

                print(ratio_list, fp_list)

                pathlib.Path("data/fixed_res_{}_{}_{}.txt".format(fingerprintLength,
                             traceLabel, label_style)).write_text(json.dumps((ratio_list, fp_list)))
            ax.set_xlabel("A/S ratio")
            ax.set_ylabel("# False positives")
            # ax.set_yscale('log')
            ax.legend()
            fig.savefig("fixed_res_{}_{}.png".format(
                fingerprintLength, traceLabel))
